"""
Study Tools Module
AI destekli Ã¶zet, sÄ±nav sorusu ve flashcard oluÅŸturma modÃ¼lÃ¼.
"""

from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
import json
import re

# ============== PROMPT ÅABLONLARI ==============

SUMMARY_PROMPT = """
Sen bir eÄŸitim asistanÄ±sÄ±n. Verilen metni analiz edip yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir Ã¶zet oluÅŸtur.

METÄ°N:
{text}

GÃ–REV: AÅŸaÄŸÄ±daki formatta bir Ã¶zet oluÅŸtur:

## ğŸ“š Konu BaÅŸlÄ±ÄŸÄ±
[Ana konu ve baÄŸlamÄ±]

## ğŸ¯ Temel Kavramlar
- [Kavram 1]: AÃ§Ä±klama
- [Kavram 2]: AÃ§Ä±klama
- [Kavram 3]: AÃ§Ä±klama

## ğŸ“ Ã–zet
[3-5 paragraf halinde ana fikirleri Ã¶zetle]

## ğŸ’¡ Ã–nemli Noktalar
1. [Ã–nemli nokta 1]
2. [Ã–nemli nokta 2]
3. [Ã–nemli nokta 3]

## ğŸ”— Ä°liÅŸkili Konular
- [Ä°lgili konu 1]
- [Ä°lgili konu 2]

TÃ¼rkÃ§e olarak yanÄ±t ver.
"""

FLASHCARD_PROMPT = """
Sen bir eÄŸitim asistanÄ±sÄ±n. Verilen metinden {count} adet bilgi kartÄ± (flashcard) oluÅŸtur.

METÄ°N:
{text}

GÃ–REV: Her kart iÃ§in aÅŸaÄŸÄ±daki JSON formatÄ±nda Ã§Ä±ktÄ± ver:

```json
[
  {{
    "question": "AÃ§Ä±k ve net bir soru",
    "answer": "KÄ±sa ve Ã¶z cevap (1-2 cÃ¼mle)",
    "difficulty": "kolay" veya "orta" veya "zor"
  }},
  ...
]
```

KURALLAR:
1. Sorular metindeki Ã¶nemli kavramlarÄ± test etmeli
2. Cevaplar kÄ±sa ve ezberlenebilir olmalÄ±
3. Zorluk seviyelerini dengeli daÄŸÄ±t
4. Sadece JSON formatÄ±nda yanÄ±t ver, baÅŸka bir ÅŸey yazma

JSON Ã§Ä±ktÄ±sÄ±:
"""

QUIZ_PROMPT = """
Sen bir eÄŸitim asistanÄ±sÄ±n. Verilen metinden {count} adet sÄ±nav sorusu oluÅŸtur.

METÄ°N:
{text}

GÃ–REV: Her soru iÃ§in aÅŸaÄŸÄ±daki JSON formatÄ±nda Ã§Ä±ktÄ± ver:

```json
[
  {{
    "type": "Ã§oktan_seÃ§meli" veya "aÃ§Ä±k_uÃ§lu" veya "doÄŸru_yanlÄ±ÅŸ",
    "question": "Soru metni",
    "options": ["A ÅŸÄ±kkÄ±", "B ÅŸÄ±kkÄ±", "C ÅŸÄ±kkÄ±", "D ÅŸÄ±kkÄ±"],
    "answer": "DoÄŸru cevap",
    "explanation": "CevabÄ±n aÃ§Ä±klamasÄ±"
  }},
  ...
]
```

KURALLAR:
1. Ã‡oktan seÃ§meli sorular iÃ§in 4 ÅŸÄ±k olmalÄ±
2. DoÄŸru/yanlÄ±ÅŸ sorularÄ± iÃ§in options boÅŸ olabilir
3. AÃ§Ä±k uÃ§lu sorular iÃ§in options boÅŸ olmalÄ±
4. Her sorunun bir aÃ§Ä±klamasÄ± olmalÄ±
5. Zorluk seviyelerini dengeli daÄŸÄ±t
6. Sadece JSON formatÄ±nda yanÄ±t ver

JSON Ã§Ä±ktÄ±sÄ±:
"""

# ============== YARDIMCI FONKSÄ°YONLAR ==============

def extract_json_from_response(response_text):
    """AI yanÄ±tÄ±ndan JSON verisini Ã§Ä±karÄ±r."""
    # Markdown kod bloÄŸu iÃ§indekileri bul
    json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', response_text)
    if json_match:
        json_str = json_match.group(1)
    else:
        # Kod bloÄŸu yoksa direkt JSON'u bul
        json_match = re.search(r'\[[\s\S]*\]', response_text)
        if json_match:
            json_str = json_match.group(0)
        else:
            json_str = response_text
    
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        # JSON parse edilemezse boÅŸ liste dÃ¶ndÃ¼r
        print(f"JSON parse hatasÄ±: {json_str[:200]}...")
        return []

def chunk_text(text, max_chunk_size=4000):
    """Uzun metni parÃ§alara bÃ¶ler."""
    if len(text) <= max_chunk_size:
        return [text]
    
    chunks = []
    paragraphs = text.split('\n\n')
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) < max_chunk_size:
            current_chunk += para + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

# ============== ANA FONKSÄ°YONLAR ==============

def generate_summary(text, model_name="llama3"):
    """
    Verilen metinden yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã¶zet oluÅŸturur.
    
    Args:
        text: Ã–zetlenecek metin
        model_name: KullanÄ±lacak Ollama modeli
    
    Returns:
        str: Markdown formatÄ±nda Ã¶zet
    """
    try:
        # Metin Ã§ok uzunsa parÃ§ala ve ana noktalarÄ± kullan
        if len(text) > 6000:
            text = text[:6000] + "\n\n[Metin kÄ±saltÄ±ldÄ±...]"
        
        prompt = ChatPromptTemplate.from_template(SUMMARY_PROMPT)
        llm = ChatOllama(model=model_name, temperature=0.3)
        chain = prompt | llm
        
        response = chain.invoke({"text": text})
        return response.content
    
    except Exception as e:
        return f"Ã–zet oluÅŸturulurken hata: {e}"

def generate_flashcards(text, count=10, model_name="llama3"):
    """
    Verilen metinden flashcard'lar oluÅŸturur.
    
    Args:
        text: Kaynak metin
        count: OluÅŸturulacak kart sayÄ±sÄ±
        model_name: KullanÄ±lacak Ollama modeli
    
    Returns:
        list: Flashcard sÃ¶zlÃ¼kleri listesi
    """
    try:
        # Metin Ã§ok uzunsa parÃ§ala
        if len(text) > 5000:
            text = text[:5000]
        
        prompt = ChatPromptTemplate.from_template(FLASHCARD_PROMPT)
        llm = ChatOllama(model=model_name, temperature=0.2)
        chain = prompt | llm
        
        response = chain.invoke({"text": text, "count": count})
        flashcards = extract_json_from_response(response.content)
        
        # Veri doÄŸrulamasÄ±
        valid_cards = []
        for card in flashcards:
            if isinstance(card, dict) and 'question' in card and 'answer' in card:
                valid_cards.append({
                    'question': card['question'],
                    'answer': card['answer'],
                    'difficulty': card.get('difficulty', 'orta')
                })
        
        return valid_cards
    
    except Exception as e:
        print(f"Flashcard oluÅŸturma hatasÄ±: {e}")
        return []

def generate_quiz(text, count=10, model_name="llama3"):
    """
    Verilen metinden sÄ±nav sorularÄ± oluÅŸturur.
    
    Args:
        text: Kaynak metin
        count: OluÅŸturulacak soru sayÄ±sÄ±
        model_name: KullanÄ±lacak Ollama modeli
    
    Returns:
        list: Soru sÃ¶zlÃ¼kleri listesi
    """
    try:
        # Metin Ã§ok uzunsa parÃ§ala
        if len(text) > 5000:
            text = text[:5000]
        
        prompt = ChatPromptTemplate.from_template(QUIZ_PROMPT)
        llm = ChatOllama(model=model_name, temperature=0.2)
        chain = prompt | llm
        
        response = chain.invoke({"text": text, "count": count})
        questions = extract_json_from_response(response.content)
        
        # Veri doÄŸrulamasÄ±
        valid_questions = []
        for q in questions:
            if isinstance(q, dict) and 'question' in q and 'answer' in q:
                valid_questions.append({
                    'type': q.get('type', 'aÃ§Ä±k_uÃ§lu'),
                    'question': q['question'],
                    'options': q.get('options', []),
                    'answer': q['answer'],
                    'explanation': q.get('explanation', '')
                })
        
        return valid_questions
    
    except Exception as e:
        print(f"SÄ±nav sorusu oluÅŸturma hatasÄ±: {e}")
        return []

def generate_study_material(text, document_id, model_name="llama3", 
                           generate_summary_=True, 
                           flashcard_count=10, 
                           quiz_count=10,
                           user_id=None):
    """
    Tek seferde tÃ¼m Ã§alÄ±ÅŸma materyallerini oluÅŸturur.
    
    Args:
        text: Kaynak metin
        document_id: VeritabanÄ±ndaki dokÃ¼man ID'si
        model_name: KullanÄ±lacak Ollama modeli
        generate_summary_: Ã–zet oluÅŸturulsun mu?
        flashcard_count: Flashcard sayÄ±sÄ±
        quiz_count: SÄ±nav sorusu sayÄ±sÄ±
        user_id: KullanÄ±cÄ± ID (multi-tenant izolasyonu iÃ§in zorunlu)
    
    Returns:
        dict: OluÅŸturulan materyaller
    """
    if user_id is None:
        raise ValueError("Security Error: generate_study_material requires user_id parameter")
    
    from modules.repo_documents import (
        create_summary, create_flashcards_bulk, create_quiz_questions_bulk, mark_document_processed
    )
    
    results = {
        'summary': None,
        'flashcards': [],
        'quiz_questions': []
    }
    
    try:
        # Ã–zet oluÅŸtur
        if generate_summary_:
            summary = generate_summary(text, model_name)
            if summary and not summary.startswith("Ã–zet oluÅŸturulurken hata"):
                create_summary(document_id, summary, user_id=user_id)
                results['summary'] = summary
        
        # Flashcard'lar oluÅŸtur
        if flashcard_count > 0:
            flashcards = generate_flashcards(text, flashcard_count, model_name)
            if flashcards:
                create_flashcards_bulk(flashcards, user_id=user_id, document_id=document_id)
                results['flashcards'] = flashcards
        
        # SÄ±nav sorularÄ± oluÅŸtur
        if quiz_count > 0:
            questions = generate_quiz(text, quiz_count, model_name)
            if questions:
                create_quiz_questions_bulk(questions, user_id=user_id, document_id=document_id)
                results['quiz_questions'] = questions
        
        # DokÃ¼manÄ± iÅŸlenmiÅŸ olarak iÅŸaretle
        mark_document_processed(document_id, user_id=user_id)
        
    except Exception as e:
        print(f"Materyal oluÅŸturma hatasÄ±: {e}")
    
    return results
